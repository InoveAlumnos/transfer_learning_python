{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RBrvkUviuj"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Ejercicio de clasificación con redes neuronales convolucionales (CNN)\n",
        "\n",
        "Ejemplo de clasificación utilizando redes neuronales convolucionales para la clasificación de imagenes<br>\n",
        "\n",
        "v1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2sSeyEovSw-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from keras.utils import to_categorical\n",
        "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior\n",
        "\n",
        "from glob import glob\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szo7P_3v00C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNSgxdfw0ix"
      },
      "source": [
        "### `Simpsons dataset`:\n",
        "El dataset **`Simpsons`** contiene 550Mbytes de imagenes a color de los personajes de los Simpsons (42 personajes). Cada imagen es de tiene al rededor de 500x450 píxeles a color (3 canales).<br> [Dataset source](https://www.kaggle.com/paultimothymooney/zipfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDz09zCY6-Gn"
      },
      "outputs": [],
      "source": [
        "# Descargar el dataset\n",
        "if os.access('./simpsons_dataset_reducido', os.F_OK) is False:\n",
        "    !curl -L -o 'simpsons_dataset_reducido.zip' 'https://drive.google.com/u/0/uc?id=1LYTxnd25-QwMIZ5bP3ErGzSHRmuGDXmc&export=download&confirm=t'\n",
        "    !unzip -q simpsons_dataset_reducido.zip\n",
        "else:\n",
        "    print(\"La carpeta ya se encuentra descargada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39D74GHn9hi1"
      },
      "outputs": [],
      "source": [
        "# Visualizar los directiorios o tipos de personas\n",
        "os.listdir(\"./simpsons_dataset_reducido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_txp_MlkjN1"
      },
      "outputs": [],
      "source": [
        " # Visualizar los tipos de personajes\n",
        " train_dir = \"./simpsons_dataset_reducido/train\"\n",
        " validation_dir = \"./simpsons_dataset_reducido/validation\"\n",
        " os.listdir(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywRZdgPa97sk"
      },
      "outputs": [],
      "source": [
        "personajes = os.listdir(train_dir)\n",
        "print(\"Cantidad de tipos de personaejs:\", len(personajes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGbCJanFR8oL"
      },
      "outputs": [],
      "source": [
        "# Visualizar las 10 primeras imagenes de un personaje\n",
        "files = glob(train_dir + \"/\" + personajes[0] + \"/**.jpg\")\n",
        "\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.axis('off')\n",
        "    img = mpimg.imread(files[i])\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYGanqnC_Ppw"
      },
      "outputs": [],
      "source": [
        "# Visualizar la dimension de la primera imagen\n",
        "img = mpimg.imread(files[0])\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syeZ_UKH_Wsm"
      },
      "outputs": [],
      "source": [
        "# Visualizar como están representados los pixeles\n",
        "print(img[85, 100:110, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF62E6R5_lDh"
      },
      "source": [
        "#### Conclusiones\n",
        "- Las imagenes tienen tamaño variable, utilizaremos un tamaño reducido para que todas las imagenes sean iguales (se elije 150x150)\n",
        "- Las imagenes están representadas de 0 a 255, hay que normalizarlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuZi82nO_4wq"
      },
      "outputs": [],
      "source": [
        "# Analizar cuantos personajes hay de cada uno\n",
        "nombre_personajes = []\n",
        "cantidad_personajes = []\n",
        "for personaje in personajes:\n",
        "    nombre_personaje = personaje.split(\"_\")[0]\n",
        "    files = glob(train_dir + \"/\" + personaje + \"/**.jpg\")\n",
        "    nombre_personajes.append(nombre_personaje)\n",
        "    cantidad_personajes.append(len(files))\n",
        "\n",
        "print(\"Cantidad de\", nombre_personajes[0], \":\", cantidad_personajes[0])\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "ax = fig.add_subplot()\n",
        "sns.barplot(x=nombre_personajes, y=cantidad_personajes, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnSk4BbBBR_t"
      },
      "source": [
        "Se puede ver que el dataset está bastante balanceado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_NjEA__fLBk"
      },
      "outputs": [],
      "source": [
        "# Descargar datos de test\n",
        "if os.access('simpsons_test', os.F_OK) is False:\n",
        "    if os.access('simpsons_test.zip', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip > simpsons_test.zip\n",
        "        else:\n",
        "            !wget simpsons_test.zip https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip\n",
        "    !unzip -q simpsons_test.zip\n",
        "else:\n",
        "    print(\"El archivo ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHsGe1Qypde"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvzaKBMbyoiy"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        directory=train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        directory=validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnzYdlRzBxz"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV05awstE6RX"
      },
      "outputs": [],
      "source": [
        "# El generador \"train_generator\" se lo puede utilizar para acceder a los datos\n",
        "# de a cantidad batch de imagenes. En este caso el generador me retornará\n",
        "# la primera vez las primeras 20 imagenes\n",
        "# El generador devuelve las imagenes (X) y las clases(personaes) a las que\n",
        "# pertenece (y)\n",
        "# X, y = train_generator.next()\n",
        "batch_imagenes, batch_clases = train_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9jbktbPF7u3"
      },
      "outputs": [],
      "source": [
        "batch_imagenes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmdCnAQ2Kd7x"
      },
      "outputs": [],
      "source": [
        "batch_clases.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGCIcOPSGSk1"
      },
      "outputs": [],
      "source": [
        "print(\"Cantidad de imagenes en el batch:\", batch_imagenes.shape[0])\n",
        "print(\"Dimensión de la imagen:\", batch_imagenes.shape[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_jnc_dqKgCt"
      },
      "outputs": [],
      "source": [
        "print(\"Cantidad de clases/personajes:\", batch_clases.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUbEzgZsGfDB"
      },
      "outputs": [],
      "source": [
        "# Observar las primeras 5 imagenes de ese batch\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "for i in range(5):\n",
        "    ax = fig.add_subplot(1, 5, i+1)\n",
        "    ax.imshow(batch_imagenes[i])\n",
        "    numero_clase = batch_clases[i].argmax()\n",
        "    ax.set_title(index_to_classes[numero_clase])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmZRSSv1JPMz"
      },
      "source": [
        "__Importante__! Luego de usar un generador \"jugando\", ese batch de imagenes que sacamos ya no se encontrará disponible para ser utilizado en el entrenamiento, es recomendable volver a crear los generadores si se los consumen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt_1BC0cKEcz"
      },
      "outputs": [],
      "source": [
        "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        directory=train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_SuZlj3gbQ"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vdIz9_r-sMe"
      },
      "outputs": [],
      "source": [
        "# Los generadores ya que encargan de transformar la salida a oneHotEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wb3oMvn-mIF"
      },
      "outputs": [],
      "source": [
        "# input shape (observado del análisis de datos)\n",
        "in_shape = (150, 150, 3)\n",
        "in_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpYcXh1g_N3Q"
      },
      "outputs": [],
      "source": [
        "# output shape (observado del análisis de datos)\n",
        "out_shape = 42\n",
        "out_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ8tQk2DMgBd"
      },
      "outputs": [],
      "source": [
        "# Debemos definir cuantas imagenes se consumiran por epoca (steps_per_epoch)\n",
        "# ya que estando el generador en el medio Keras no puede saberlo por\n",
        "# su cuenta\n",
        "steps_per_epoch_train = len(train_generator)\n",
        "steps_per_epoch_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-ThxJzgmEmj"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch_validation = len(validation_generator)\n",
        "steps_per_epoch_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu1u9JhXq9Dy"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Ahora agregaremos más pares de capas CONV + POOL a fin de reducir más la\n",
        "# dimensión de la imagen antes de llegar a la capa flatten\n",
        "# Otra estrategia es ir aumentando la cantidad de filtros a medida que crece\n",
        "# la profundidad de la red\n",
        "\n",
        "# convolucional f=(3,3), # de filtros: 8, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model.add(Conv2D(filters = 8, kernel_size = (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
        "# convolucional f=(3,3), # de filtros: 16, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model.add(Conv2D(filters = 16, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "# convolucional f=(3,3), # de filtros: 32, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "# convolucional f=(3,3), # de filtros: 64, activación relu\n",
        "# max pooling f=2, s=2\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "# capa flatten\n",
        "model.add(Flatten())\n",
        "# capa densa de 64 elementos activación relu\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "# capa densa con un output de 10 elemento con activación softmax\n",
        "model.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_89g3dSm2wf"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=steps_per_epoch_train,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=steps_per_epoch_validation,\n",
        "      epochs=10\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDuagYJHvNlm"
      },
      "outputs": [],
      "source": [
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='val')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsH5q9y6Qt1-"
      },
      "outputs": [],
      "source": [
        "# Predecir los datos\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        directory=\"./simpsons_test\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=10,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "y_hat_prob = model.predict(test_generator)\n",
        "y_hat_prob[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxs4EZSBAZoh"
      },
      "outputs": [],
      "source": [
        "y_hat = np.argmax(y_hat_prob,axis=1)\n",
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBqoGBsIS4Rr"
      },
      "outputs": [],
      "source": [
        "#¿Cómo obtenemos el \"y\" verdadero?\n",
        "test_generator.filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaIy0eJFS_bn"
      },
      "outputs": [],
      "source": [
        "# Muy rebuscada esta forma de obtener los nombres de los personajes!\n",
        "# Pero en general cuando tenemos los datos de test no tenemos los nombres\n",
        "# por lo que no tenemos el \"y\" verdadero\n",
        "personajes_test = []\n",
        "for file in test_generator.filenames:\n",
        "    image_name = os.path.basename(file)\n",
        "    image_name_split = image_name.split(\"_\")\n",
        "    personaje_name_split = image_name_split[:len(image_name_split)-1]\n",
        "    personaje = personaje_name_split[0]\n",
        "    for name in personaje_name_split[1:]:\n",
        "        personaje += \"_\" + name\n",
        "    personajes_test.append(personaje)\n",
        "personajes_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUeviz_CUXlK"
      },
      "outputs": [],
      "source": [
        "# Obtener el \"y\" verdadero\n",
        "y_test = [train_generator.class_indices[personaje] for personaje in personajes_test]\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww_S7M1lw9oT"
      },
      "outputs": [],
      "source": [
        "# Descargar el modelo entrenado para usar en el futuro sin tener\n",
        "# que volver a entrenarlo\n",
        "model.save(\"cnn_simpsons_reducido.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3IfjUuI4XnD"
      },
      "source": [
        "# Validar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnXeXHwdyHVx"
      },
      "outputs": [],
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeLeYLYz6ZhO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_hat)\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=range(47))\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZxGbjG96jR"
      },
      "source": [
        "# Utilizar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Tc5nBqbow8"
      },
      "source": [
        "Se utiliza el ranking de los peores 10 números clasificados con una ANN para evlauar contra este nuevo modelo de red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noOsuU6Tb4GZ"
      },
      "outputs": [],
      "source": [
        "batch_test = test_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cefy3ktFb6j6"
      },
      "outputs": [],
      "source": [
        "# Observar las primeras 5 imagenes de ese batch\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(batch_test[i])\n",
        "    numero_clase = y_hat[i]\n",
        "    ax.set_title(index_to_classes[numero_clase])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yzVZcZ9-4m"
      },
      "source": [
        "# Conclusión\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWAReOgo-B7b"
      },
      "source": [
        "Se pudo ver en este ejemplo que el hecho de haber reducido el tamaño del dataset hizo que el entrenamiento se hiciera más rápido pero se produjo overfitting, el sistema durante el entrenamiento (train) creo que está logrando buenos resultados pero la validación no lo acompaña. Se puede ver que la cantidad de datos es FUNDAMENTAL en deep learning."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}