{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67RBrvkUviuj"
   },
   "source": [
    "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
    "\n",
    "\n",
    "# Ejercicio de clasificación con redes neuronales convolucionales (CNN)\n",
    "\n",
    "Ejemplo de clasificación utilizando redes neuronales convolucionales para la clasificación de imagenes<br>\n",
    "\n",
    "v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2sSeyEovSw-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "#from keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Szo7P_3v00C"
   },
   "source": [
    "# Recolectar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbNSgxdfw0ix"
   },
   "source": [
    "### `Simpsons dataset`:\n",
    "El dataset **`Simpsons`** contiene 550Mbytes de imagenes a color de los personajes de los Simpsons (42 personajes). Cada imagen es de tiene al rededor de 500x450 píxeles a color (3 canales).<br> [Dataset source](https://www.kaggle.com/paultimothymooney/zipfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDz09zCY6-Gn",
    "outputId": "9b9d9a78-e405-49ec-e2be-7f1095924837"
   },
   "outputs": [],
   "source": [
    "# Descargar el dataset\n",
    "import gdown\n",
    "if os.access('simpsons_dataset_reducido', os.F_OK) is False:\n",
    "    if os.access('simpsons_dataset_reducido.zip', os.F_OK) is False:\n",
    "        url = 'https://drive.google.com/uc?id=1LYTxnd25-QwMIZ5bP3ErGzSHRmuGDXmc'\n",
    "        output = 'simpsons_dataset_reducido.zip'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "    !unzip -q simpsons_dataset_reducido.zip\n",
    "else:\n",
    "    print(\"El archivo ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39D74GHn9hi1",
    "outputId": "4627e85e-bd88-4196-f5b9-a16d0d9a91bd"
   },
   "outputs": [],
   "source": [
    "# Visualizar los directiorios o tipos de personas\n",
    "os.listdir(\"./simpsons_dataset_reducido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_txp_MlkjN1",
    "outputId": "4c4c6d0b-de95-48a0-9c43-646cc0f85057"
   },
   "outputs": [],
   "source": [
    " # Visualizar los tipos de personajes\n",
    " train_dir = \"./simpsons_dataset_reducido/train\"\n",
    " validation_dir = \"./simpsons_dataset_reducido/validation\"\n",
    " os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywRZdgPa97sk",
    "outputId": "a5622bd9-6857-4c3f-b0b2-51210e469a03"
   },
   "outputs": [],
   "source": [
    "personajes = os.listdir(train_dir)\n",
    "print(\"Cantidad de tipos de personaejs:\", len(personajes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "rGbCJanFR8oL",
    "outputId": "b11c933d-c5a2-4336-b39e-b420d7969564"
   },
   "outputs": [],
   "source": [
    "# Visualizar las 10 primeras imagenes de un personaje\n",
    "files = glob(train_dir + \"/\" + personajes[0] + \"/**.jpg\")\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.axis('off')\n",
    "    img = mpimg.imread(files[i])\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYGanqnC_Ppw",
    "outputId": "3d263403-4164-447a-83da-f7ed053d7265"
   },
   "outputs": [],
   "source": [
    "# Visualizar la dimension de la primera imagen\n",
    "img = mpimg.imread(files[0])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syeZ_UKH_Wsm",
    "outputId": "f78a3aa7-fa7b-4053-daeb-161d61686286"
   },
   "outputs": [],
   "source": [
    "# Visualizar como están representados los pixeles\n",
    "print(img[85, 100:110, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF62E6R5_lDh"
   },
   "source": [
    "#### Conclusiones\n",
    "- Las imagenes tienen tamaño variable, utilizaremos un tamaño reducido para que todas las imagenes sean iguales (se elije 150x150)\n",
    "- Las imagenes están representadas de 0 a 255, hay que normalizarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "CuZi82nO_4wq",
    "outputId": "ab6e1285-a6ed-407c-db94-bbc9d996842e"
   },
   "outputs": [],
   "source": [
    "# Analizar cuantos personajes hay de cada uno\n",
    "nombre_personajes = []\n",
    "cantidad_personajes = []\n",
    "for personaje in personajes:\n",
    "    nombre_personaje = personaje.split(\"_\")[0]\n",
    "    files = glob(train_dir + \"/\" + personaje + \"/**.jpg\")\n",
    "    nombre_personajes.append(nombre_personaje)\n",
    "    cantidad_personajes.append(len(files))\n",
    "\n",
    "print(\"Cantidad de\", nombre_personajes[0], \":\", cantidad_personajes[0])\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "ax = fig.add_subplot()\n",
    "sns.barplot(x=nombre_personajes, y=cantidad_personajes, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnSk4BbBBR_t"
   },
   "source": [
    "Se puede ver que el dataset está bastante balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_NjEA__fLBk",
    "outputId": "8bded340-aa0c-4d87-8c5c-231b0c26b7a0"
   },
   "outputs": [],
   "source": [
    "# Descargar datos de test\n",
    "if os.access('simpsons_test', os.F_OK) is False:\n",
    "    if os.access('simpsons_test.zip', os.F_OK) is False:\n",
    "        if platform.system() == 'Windows':\n",
    "            !curl https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip > simpsons_test.zip\n",
    "        else:\n",
    "            !wget simpsons_test.zip https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip\n",
    "    !unzip -q simpsons_test.zip\n",
    "else:\n",
    "    print(\"El archivo ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHHsGe1Qypde"
   },
   "source": [
    "# Procesar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvzaKBMbyoiy",
    "outputId": "16a5af52-6ac4-4ace-eacd-8572270c60ae"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
    "# y agregando deformación (data augmentation)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,   # Normalización\n",
    "    rotation_range=40, # Rotación -40º a 40º\n",
    "    width_shift_range=0.2, # Desplazamiento horizontal\n",
    "    height_shift_range=0.2, # Desplazamiento vertical\n",
    "    shear_range=0.2, # Ángulo de corte\n",
    "    zoom_range=0.2,  # Zoom\n",
    "    horizontal_flip=True) # Espejar la imagen\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=140,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        directory=validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=80,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BnzYdlRzBxz"
   },
   "source": [
    "# Explorar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV05awstE6RX"
   },
   "outputs": [],
   "source": [
    "# El generador \"train_generator\" se lo puede utilizar para acceder a los datos\n",
    "# de a cantidad batch de imagenes. En este caso el generador me retornará\n",
    "# la primera vez las primeras 20 imagenes\n",
    "# El generador devuelve las imagenes (X) y las clases(personaes) a las que\n",
    "# pertenece (y)\n",
    "# X, y = train_generator.next()\n",
    "batch_imagenes, batch_clases = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9jbktbPF7u3",
    "outputId": "917126d0-efba-4a8d-f168-8e34417e770f"
   },
   "outputs": [],
   "source": [
    "batch_imagenes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmdCnAQ2Kd7x",
    "outputId": "b8d63e76-b2cf-449e-94e1-55caa5f9300e"
   },
   "outputs": [],
   "source": [
    "batch_clases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGCIcOPSGSk1",
    "outputId": "b8722f83-f2a7-4a7d-ab8b-658b22b82857"
   },
   "outputs": [],
   "source": [
    "print(\"Cantidad de imagenes en el batch:\", batch_imagenes.shape[0])\n",
    "print(\"Dimensión de la imagen:\", batch_imagenes.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_jnc_dqKgCt",
    "outputId": "0c94b907-a1c7-4162-dd19-14b0de7d3194"
   },
   "outputs": [],
   "source": [
    "print(\"Cantidad de clases/personajes:\", batch_clases.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "dUbEzgZsGfDB",
    "outputId": "82d1a46a-ff6f-4f7e-de2e-e7f5ad23a8c5"
   },
   "outputs": [],
   "source": [
    "# Observar las primeras 5 imagenes de ese batch\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i+1)\n",
    "    ax.imshow(batch_imagenes[i])\n",
    "    numero_clase = batch_clases[i].argmax()\n",
    "    ax.set_title(index_to_classes[numero_clase])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmZRSSv1JPMz"
   },
   "source": [
    "__Importante__! Luego de usar un generador \"jugando\", ese batch de imagenes que sacamos ya no se encontrará disponible para ser utilizado en el entrenamiento, es recomendable volver a crear los generadores si se los consumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wt_1BC0cKEcz",
    "outputId": "c6966568-ce9b-4f6a-b669-6206c7c49379"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=140,\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z_SuZlj3gbQ"
   },
   "source": [
    "# Entrenar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vdIz9_r-sMe"
   },
   "outputs": [],
   "source": [
    "# Los generadores ya que encargan de transformar la salida a oneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Wb3oMvn-mIF",
    "outputId": "71454f22-872f-4ffe-ddf8-a146880806f7"
   },
   "outputs": [],
   "source": [
    "# input shape (observado del análisis de datos)\n",
    "in_shape = (150, 150, 3)\n",
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpYcXh1g_N3Q",
    "outputId": "c09c6db5-0381-45bc-a1d4-d5cbe631fbaf"
   },
   "outputs": [],
   "source": [
    "# output shape (observado del análisis de datos)\n",
    "out_shape = 42\n",
    "out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQ8tQk2DMgBd",
    "outputId": "487db1ce-e807-4814-a876-1b289fad31aa"
   },
   "outputs": [],
   "source": [
    "# Debemos definir cuantas imagenes se consumiran por epoca (steps_per_epoch)\n",
    "# ya que estando el generador en el medio Keras no puede saberlo por\n",
    "# su cuenta\n",
    "steps_per_epoch_train = len(train_generator)\n",
    "steps_per_epoch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-ThxJzgmEmj",
    "outputId": "2db8b553-068c-4dc6-850d-23c42715fd07"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_validation = len(validation_generator)\n",
    "steps_per_epoch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fu1u9JhXq9Dy",
    "outputId": "f528c149-55f0-44ca-9ae8-50050193f880"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Ahora agregaremos más pares de capas CONV + POOL a fin de reducir más la\n",
    "# dimensión de la imagen antes de llegar a la capa flatten\n",
    "# Otra estrategia es ir aumentando la cantidad de filtros a medida que crece\n",
    "# la profundidad de la red\n",
    "\n",
    "# convolucional f=(3,3), # de filtros: 8, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model.add(Conv2D(filters = 8, kernel_size = (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "# convolucional f=(3,3), # de filtros: 16, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# convolucional f=(3,3), # de filtros: 32, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# convolucional f=(3,3), # de filtros: 64, activación relu\n",
    "# max pooling f=2, s=2\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "# capa flatten\n",
    "model.add(Flatten())\n",
    "# capa densa de 64 elementos activación relu\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "# capa densa con un output de 10 elemento con activación softmax\n",
    "model.add(Dense(units=out_shape, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_89g3dSm2wf",
    "outputId": "ae8cc78b-5f03-4747-8aad-c97adf9a1c07"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=steps_per_epoch_train,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=steps_per_epoch_validation,\n",
    "      epochs=30\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "xDuagYJHvNlm",
    "outputId": "5971ff45-8bda-4da5-baee-ab14e24abb7b"
   },
   "outputs": [],
   "source": [
    "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsH5q9y6Qt1-",
    "outputId": "b631c54e-b0f2-4e66-9bf3-461f7facefb7"
   },
   "outputs": [],
   "source": [
    "# Predecir los datos\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        directory=\"./simpsons_test\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=10,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "y_hat_prob = model.predict(test_generator)\n",
    "y_hat_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxs4EZSBAZoh",
    "outputId": "ce747612-1a04-4001-db8d-a0c1b49afea6"
   },
   "outputs": [],
   "source": [
    "y_hat = np.argmax(y_hat_prob,axis=1)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBqoGBsIS4Rr",
    "outputId": "644ac042-889a-4bc0-f6e9-24c465fa541d"
   },
   "outputs": [],
   "source": [
    "#¿Cómo obtenemos el \"y\" verdadero?\n",
    "test_generator.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaIy0eJFS_bn",
    "outputId": "d622edfa-cb97-48c6-8a0a-a5f5d8268b4a"
   },
   "outputs": [],
   "source": [
    "# Muy rebuscada esta forma de obtener los nombres de los personajes!\n",
    "# Pero en general cuando tenemos los datos de test no tenemos los nombres\n",
    "# por lo que no tenemos el \"y\" verdadero\n",
    "personajes_test = []\n",
    "for file in test_generator.filenames:\n",
    "    image_name = os.path.basename(file)\n",
    "    image_name_split = image_name.split(\"_\")\n",
    "    personaje_name_split = image_name_split[:len(image_name_split)-1]\n",
    "    personaje = personaje_name_split[0]\n",
    "    for name in personaje_name_split[1:]:\n",
    "        personaje += \"_\" + name\n",
    "    personajes_test.append(personaje)\n",
    "personajes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUeviz_CUXlK",
    "outputId": "cc1c73c5-55a6-47dc-b26c-ef4f9097b72b"
   },
   "outputs": [],
   "source": [
    "# Obtener el \"y\" verdadero\n",
    "y_test = [train_generator.class_indices[personaje] for personaje in personajes_test]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww_S7M1lw9oT"
   },
   "outputs": [],
   "source": [
    "# Descargar el modelo entrenado para usar en el futuro sin tener\n",
    "# que volver a entrenarlo\n",
    "model.save(\"cnn_simpsons_augmented.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IfjUuI4XnD"
   },
   "source": [
    "# Validar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnXeXHwdyHVx",
    "outputId": "690906df-2f66-41c5-86f2-1f12854f6326"
   },
   "outputs": [],
   "source": [
    "# Calcular la exactitud (accuracy)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "TeLeYLYz6ZhO",
    "outputId": "b694afa2-7a4e-4c7b-eea5-2ff4e04bba82"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=range(47))\n",
    "cmd.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dZxGbjG96jR"
   },
   "source": [
    "# Utilizar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6Tc5nBqbow8"
   },
   "source": [
    "Se utiliza el ranking de los peores 10 números clasificados con una ANN para evlauar contra este nuevo modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noOsuU6Tb4GZ"
   },
   "outputs": [],
   "source": [
    "batch_test = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "Cefy3ktFb6j6",
    "outputId": "5b2a7b8a-8a46-4aa4-adab-eefd4f0ac246"
   },
   "outputs": [],
   "source": [
    "# Observar las primeras 5 imagenes de ese batch\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.imshow(batch_test[i])\n",
    "    numero_clase = y_hat[i]\n",
    "    ax.set_title(index_to_classes[numero_clase])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7yzVZcZ9-4m"
   },
   "source": [
    "# Conclusión\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWAReOgo-B7b"
   },
   "source": [
    "En el ejemplo de este notebook se puede observar que al agregar data augmentation evitamos el overfitting, los resultados del entrenamiento alcanzan a la validación pero el sistema no llega a aprender del todo las características de los personajes. Data augmentation no reemplaza del todo la falta de datos, pero es mejor que nada."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_simpsons_augmented.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}