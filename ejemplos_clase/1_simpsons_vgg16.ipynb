{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RBrvkUviuj"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Ejercicio de clasificación con redes neuronales convolucionales (CNN)\n",
        "\n",
        "Ejemplo de clasificación utilizando transfer learning y redes neuronales convolucionales para la clasificación de imagenes<br>\n",
        "\n",
        "v1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objetivos:**\n",
        "* Estudiar el dataset de los Simpsons.\n",
        "* Implementar Transfer Learning y Redes Convolucionales para la clasificación de imágenes de los Simpsons."
      ],
      "metadata": {
        "id": "LCXZ3T2asLkB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2sSeyEovSw-"
      },
      "outputs": [],
      "source": [
        "#Librerias a implementar\n",
        "import os\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "#from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior\n",
        "\n",
        "from glob import glob\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "“El Transfer Learning, o aprendizaje transferido en español, se refiere al conjunto de métodos que permiten transferir conocimientos adquiridos gracias a la resolución de problemas para resolver otros problemas.”\n",
        "\n",
        "Fuente: https://datascientest.com/es/que-es-el-transfer-learning"
      ],
      "metadata": {
        "id": "AVpnbB0qsBry"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szo7P_3v00C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNSgxdfw0ix"
      },
      "source": [
        "### `Simpsons dataset`:\n",
        "El dataset **`Simpsons`** contiene 550Mbytes de imagenes a color de los personajes de los Simpsons (42 personajes). Cada imagen es de tiene al rededor de 500x450 píxeles a color (3 canales).<br> [Dataset source](https://www.kaggle.com/paultimothymooney/zipfiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código de descarga del dataset: simpsons_dataset_reducido"
      ],
      "metadata": {
        "id": "aM_XQClnsoyp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDz09zCY6-Gn"
      },
      "outputs": [],
      "source": [
        "if os.access('./simpsons_dataset_reducido', os.F_OK) is False:\n",
        "    !curl -L -o 'simpsons_dataset_reducido.zip' 'https://drive.google.com/u/0/uc?id=1LYTxnd25-QwMIZ5bP3ErGzSHRmuGDXmc&export=download&confirm=t'\n",
        "    !unzip -q simpsons_dataset_reducido.zip\n",
        "else:\n",
        "    print(\"La carpeta ya se encuentra descargada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39D74GHn9hi1"
      },
      "outputs": [],
      "source": [
        "# Visualizar los directiorios o tipos de personas\n",
        "os.listdir(\"./simpsons_dataset_reducido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_txp_MlkjN1"
      },
      "outputs": [],
      "source": [
        " # Visualizar los tipos de personajes\n",
        "train_dir = \"./simpsons_dataset_reducido/train\"\n",
        "validation_dir = \"./simpsons_dataset_reducido/validation\"\n",
        "# Observar los nombres de las carpetas internas en la ruta especificada.\n",
        "os.listdir(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "personaje_dir = \"./simpsons_dataset_reducido/train/principal_skinner\"\n",
        "cantidad = os.listdir(personaje_dir)\n",
        "len(cantidad)"
      ],
      "metadata": {
        "id": "z6zZvABfpzhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywRZdgPa97sk"
      },
      "outputs": [],
      "source": [
        "# Almacena los nombres de las carpetas internas de la ruta especificada.\n",
        "personajes = os.listdir(train_dir)\n",
        "\n",
        "# Cantidad de tipos de personajes:\n",
        "print(\"Cantidad de tipos de personajes:\", len(personajes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir"
      ],
      "metadata": {
        "id": "c79ojmlJq7Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob(train_dir + \"/\" + personajes[0] + \"/**.jpg\")\n",
        "files"
      ],
      "metadata": {
        "id": "kguPaufBq0nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGbCJanFR8oL"
      },
      "outputs": [],
      "source": [
        "# Visualizar las 10 primeras imagenes de un personaje\n",
        "# glob(), encuentra todos los nombres de rutas que se asemejan a un patrón especificado de acuerdo a las reglas que se siguen.\n",
        "files = glob(train_dir + \"/\" + personajes[0] + \"/**.jpg\")\n",
        "\n",
        "# plt alias de Matplotlib.\n",
        "# Método figure() crea el espacio para dibujar.\n",
        "# Con figsize=(16,9) se define el ancho y alto del dibujo\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "# Bucle que itera 10 veces para mostrar las primeras 10 imágenes del dataset\n",
        "for i in range(10):\n",
        "\n",
        "    # ax gráfico que mostrará las imágenes en 2 filas y 5 columnas\n",
        "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "\n",
        "    # .axis('off') elimina el recuadro de cada imagen\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Herramienta de Matplotlib para para leer imágenes\n",
        "    img = mpimg.imread(files[i]) # './simpsons_dataset_reducido/train/patty_bouvier/pic_0007.jpg',\n",
        "\n",
        "    # Muestra las imágenes de la variable data_X_train en el espacio del dibujo\n",
        "    plt.imshow(img)\n",
        "\n",
        "# Muestra la figura\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYGanqnC_Ppw"
      },
      "outputs": [],
      "source": [
        "# Visualizar la dimension de la primera imagen\n",
        "img = mpimg.imread(files[0])\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syeZ_UKH_Wsm"
      },
      "outputs": [],
      "source": [
        "# Visualizar como están representados los pixeles internos.\n",
        "print(img[85, 100:110, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF62E6R5_lDh"
      },
      "source": [
        "#### Conclusiones\n",
        "- Las imagenes tienen tamaño variable, utilizaremos un tamaño reducido para que todas las imagenes sean iguales (se elije 150x150)\n",
        "- Las imagenes están representadas de 0 a 255, hay que normalizarlas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observar que tan balanceado está el dataset"
      ],
      "metadata": {
        "id": "-GM5Ep8Px4Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "personajes[:4]"
      ],
      "metadata": {
        "id": "-lqBeItEsJAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuZi82nO_4wq"
      },
      "outputs": [],
      "source": [
        "# Analizar cuantos personajes hay de cada uno\n",
        "nombre_personajes = []\n",
        "cantidad_personajes = []\n",
        "\n",
        "# Bucle que itera la lista de personajes\n",
        "for personaje in personajes:\n",
        "\n",
        "    # Almacena la ruta completa de cada imagen\n",
        "    files = glob(train_dir + \"/\" + personaje + \"/**.jpg\")\n",
        "\n",
        "    # Por cada nombre de imagen separa por _\n",
        "    nombre_personaje = personaje.split(\"_\")[0]\n",
        "\n",
        "    # Almacena el nombre de cada personaje en una lista\n",
        "    nombre_personajes.append(nombre_personaje)\n",
        "\n",
        "    # Almacena la cantidad de rutas que es igual a la cantidad de personajes\n",
        "    cantidad_personajes.append(len(files))\n",
        "\n",
        "# Graficar la cantidad de imágenes que tiene cada personaje\n",
        "# plt alias de Matplotlib.\n",
        "# Método figure() crea el espacio para dibujar.\n",
        "# Con figsize=(16,9) se define el ancho y alto del dibujo\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "# espacio ax para el gráfico a mostrar\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "# Gráfico de barra (barplot)\n",
        "# sns, alias de Seaborn\n",
        "# ax=ax, los datos se representarán en horiizontal\n",
        "sns.barplot(x=nombre_personajes, y=cantidad_personajes, ax=ax)\n",
        "\n",
        "# Mostrar la imagen.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnSk4BbBBR_t"
      },
      "source": [
        "Se puede ver que el dataset está bastante balanceado"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código de descarga del dataset: simpsons_test"
      ],
      "metadata": {
        "id": "iC5_k35vxuwK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_NjEA__fLBk"
      },
      "outputs": [],
      "source": [
        "# Descargar datos de test\n",
        "if os.access('simpsons_test', os.F_OK) is False:\n",
        "    if os.access('simpsons_test.zip', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip > simpsons_test.zip\n",
        "        else:\n",
        "            !wget simpsons_test.zip https://github.com/InoveAlumnos/dataset_analytics_python/raw/master/simpsons_test.zip\n",
        "    !unzip -q simpsons_test.zip\n",
        "else:\n",
        "    print(\"El archivo ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHsGe1Qypde"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvzaKBMbyoiy"
      },
      "outputs": [],
      "source": [
        "# Se importa ImageDataGenerator del módulo de keras.preprocessing.image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# El método .flow_from_directory, toma la ruta a un directorio y genera lotes de datos aumentados.\n",
        "# target_size, se indica la dimensión de la imagen que se desea.\n",
        "# batch_size, la cantidad que va a tomar para aplicar la operación de escalado.\n",
        "# class_mode, es categorical ya que son varios personajes.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        directory=train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=140,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "# Mismo proceso para los datos de validación\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        directory=validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=80,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "# Con dict, arma un diccionario\n",
        "# con zip, es una función toma que iterables como argumentos y devuelve un iterador.\n",
        "# Es decir, se construye en diccionario indice:valor --> ubicacion:nombre_personaje\n",
        "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\n",
        "#index_to_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnzYdlRzBxz"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV05awstE6RX"
      },
      "outputs": [],
      "source": [
        "# El generador \"train_generator\" se lo puede utilizar para acceder a los datos\n",
        "# de a cantidad batch de imagenes. En este caso el generador me retornará\n",
        "# la primera vez las primeras 20 imagenes\n",
        "# El generador devuelve las imagenes (X) y las clases(personaes) a las que\n",
        "# pertenece (y)\n",
        "# X, y = train_generator.next()\n",
        "batch_imagenes, batch_clases = train_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9jbktbPF7u3"
      },
      "outputs": [],
      "source": [
        "# Cantidad de imágenes, dimensión alto, dimensión ancho, canales de color\n",
        "batch_imagenes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmdCnAQ2Kd7x"
      },
      "outputs": [],
      "source": [
        "# Cantidad de imágenes categorías (representadas por cada personaje)\n",
        "batch_clases.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGCIcOPSGSk1"
      },
      "outputs": [],
      "source": [
        "# Cantidad de imágenes.\n",
        "print(\"Cantidad de imagenes en el batch:\", batch_imagenes.shape[0])\n",
        "\n",
        "# Dimensión alto, dimensión ancho, canales de color\n",
        "print(\"Dimensión de la imagen:\", batch_imagenes.shape[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_jnc_dqKgCt"
      },
      "outputs": [],
      "source": [
        "# batch_clases, variable que contiene la cantidad de personajes.\n",
        "print(\"Cantidad de clases/personajes:\", batch_clases.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUbEzgZsGfDB"
      },
      "outputs": [],
      "source": [
        "# Observar las primeras 5 imagenes de ese batch\n",
        "# plt alias de Matplotlib.\n",
        "# Método figure() crea el espacio para dibujar.\n",
        "# Con figsize=(16,9) se define el ancho y alto del dibujofig = plt.figure(figsize=(16,9))\n",
        "# Observar las primeras 5 imagenes de ese batch\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "# Itera 5 veces\n",
        "for i in range(5):\n",
        "\n",
        "    # ax, gráfico que mostrará las imágenes en 1 filas y 5 columnas\n",
        "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
        "    ax = fig.add_subplot(1, 5, i+1)\n",
        "\n",
        "    # Muestra la imagen\n",
        "    ax.imshow(batch_imagenes[i])\n",
        "\n",
        "    # Ubica por la posición de la imagen el nombre que le corresponde.\n",
        "    numero_clase = batch_clases[i].argmax()\n",
        "\n",
        "    # A cada imagen le agrega un titulo que sería el nombre del personaje que le corresponde.\n",
        "    ax.set_title(index_to_classes[numero_clase])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmZRSSv1JPMz"
      },
      "source": [
        "__Importante__! Luego de usar un generador \"jugando\", ese batch de imagenes que sacamos ya no se encontrará disponible para ser utilizado en el entrenamiento, es recomendable volver a crear los generadores si se los consumen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt_1BC0cKEcz"
      },
      "outputs": [],
      "source": [
        "# Crear un generador, indicando si deseamos realizar un escalado de la imagen\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# El método .flow_from_directory, toma la ruta a un directorio y genera lotes de datos aumentados.\n",
        "# target_size, se indica la dimensión de la imagen que se desea.\n",
        "# batch_size, la cantidad que va a tomar para aplicar la operación de escalado.\n",
        "# class_mode, es categorical ya que son varios personajes.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        directory=train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=140,\n",
        "        class_mode=\"categorical\")\n",
        "\n",
        "# Con dict, arma un diccionario\n",
        "# con zip, es una función toma que iterables como argumentos y devuelve un iterador.\n",
        "# Es decir, se construye en diccionario indice:valor --> ubicacion:nombre_personaje\n",
        "index_to_classes = dict(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_SuZlj3gbQ"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###NOTE: Los generadores ya se encargan de transformar la salida a oneHotEncoding"
      ],
      "metadata": {
        "id": "uSFnfr_Pzyv5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wb3oMvn-mIF"
      },
      "outputs": [],
      "source": [
        "# input shape (observado del análisis de datos)\n",
        "# Almacena las dimensiones y los canales de color, sería la entrada a la red\n",
        "in_shape = (150, 150, 3)\n",
        "in_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpYcXh1g_N3Q"
      },
      "outputs": [],
      "source": [
        "# output shape (observado del análisis de datos)\n",
        "# 42 ya que representa categorías, los nombres de los personajes con lo que se entrena la red\n",
        "out_shape = 42\n",
        "out_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ8tQk2DMgBd"
      },
      "outputs": [],
      "source": [
        "# Debemos definir cuantas imagenes se consumiran por epoca para entrenamiento(steps_per_epoch)\n",
        "# ya que estando el generador en el medio Keras no puede saberlo por\n",
        "# su cuenta\n",
        "steps_per_epoch_train = len(train_generator)\n",
        "steps_per_epoch_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-ThxJzgmEmj"
      },
      "outputs": [],
      "source": [
        "# Debemos definir cuantas imagenes se consumiran por epoca para validación (steps_per_epoch)\n",
        "# ya que estando el generador en el medio Keras no puede saberlo por\n",
        "# su cuenta\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "steps_per_epoch_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeoJHK4U2xJi"
      },
      "outputs": [],
      "source": [
        "# Se importa VGG16 de la librería tensorflow.keras.applications\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Traemos el modelo VGG16 pre entrenado con los pesos\n",
        "# obtenidos del dataset de ImageNet\n",
        "# include_top=False, indicamos que no deseamos las ultimas capas\n",
        "# de clasificación de la red (include_top=False)\n",
        "# Indicamos que no deseamos que los pesos de la red\n",
        "# sean entrenados (vgg_base.trainable=False)\n",
        "# weights='imagenet', entrenamiento previo en ImageNet\n",
        "\n",
        "vgg_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=in_shape)\n",
        "vgg_base.trainable=False\n",
        "\n",
        "# Estructura de la red\n",
        "vgg_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu1u9JhXq9Dy"
      },
      "outputs": [],
      "source": [
        "# Se importa Dense,  Dropout, Flatten de la librería keras.layers\n",
        "# Se importa Conv2D, MaxPooling2D  de la librería keras.layers.convolutional\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "# Se crea el objeto model1 a partir de la clase Sequential()\n",
        "model = Sequential()\n",
        "\n",
        "# Incluir al modelo la red vgg_base traida de VGG16\n",
        "model.add(vgg_base)\n",
        "\n",
        "# Ahora agregaremos más pares de capas CONV + POOL a fin de reducir más la\n",
        "# dimensión de la imagen antes de llegar a la capa flatten\n",
        "# Otra estrategia es ir aumentando la cantidad de filtros a medida que crece\n",
        "# la profundidad de la red\n",
        "\n",
        "# Capa de comunicación entre la red convolucional y la red neuronal\n",
        "model.add(Flatten())\n",
        "\n",
        "# Red Neuronal que inicia con 128 neuronas y la función de activación \"relu\"\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "# Se agrega una capa de dropout para dormir parte de las neuronas.\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "# Red Neuronal que inicia con 64 neuronas y la función de activación \"relu\"\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "# Capa de salida con la cantidad de personajes y 'softmax' porque es multicategorical\n",
        "model.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "# Configuración del modelo para el entrenamiento, implementando el método compile a partir del modelo creado.\n",
        "# Se necesita indicar los parámetros:\n",
        "# optimizer, nombre del optimizador (es el algoritmo que se encarga del descenso de gradiente estocástico)\n",
        "# Fuente: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "# loss, se llama función de pérdida, representa las categorías conocidas de las predicción. Al ser 'categorical_crossentropy'\n",
        "#la predicción tiene una salida con varias opciones.\n",
        "# metrics, se define la métrica que evaluará el modelo durante el entrenamiento y las pruebas.\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_89g3dSm2wf"
      },
      "outputs": [],
      "source": [
        "# Se entrena el modelo con el método fit\n",
        "# Necesita definir los valores para train_generator, la cantidad de épocas que seria la iteraciones de entrenamiento y\n",
        "# steps_per_epoch, cantidad de imágenes a consumir la red por época.\n",
        "# validation_steps, cantidad de imágenes para validación\n",
        "# validation_data, imagénes preprocesadas.\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=steps_per_epoch_train,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=steps_per_epoch_validation,\n",
        "      epochs=20\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDuagYJHvNlm"
      },
      "outputs": [],
      "source": [
        "# Variable epoch_count, que almacena en una lista la cantidad de épocas de train\n",
        "# history, es la variable que almacena las predicciones del modelo\n",
        "# y de ella, se puede acceder a información como su historial (history) del accuracy y val_accuracy\n",
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "# De Seaborn (sns) se accede al gráfico de línea para representar el 'accuracy' y val_accuracy\n",
        "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='val')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSJoyypDptbY"
      },
      "outputs": [],
      "source": [
        "# Estructura de la red neuronal con vgg_16\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsH5q9y6Qt1-"
      },
      "outputs": [],
      "source": [
        "# Predecir los datos\n",
        "# Crear un generador, indicando para realizar un escalado de la imagen\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# El método .flow_from_directory, toma la ruta a un directorio y genera lotes de datos aumentados.\n",
        "# target_size, se indica la dimensión de la imagen que se desea.\n",
        "# batch_size, la cantidad que va a tomar para aplicar la operación de escalado.\n",
        "# class_mode, es categorical ya que son varios personajes.\n",
        "# shuffle, sin desordenar\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        directory=\"./simpsons_test\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=10,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "# Predecir los datos a partir de los datos de test (test_generator)\n",
        "y_hat_prob = model.predict(test_generator)\n",
        "\n",
        "# Resultado de la predicción de la primer imagen.\n",
        "# Muestra las probabilidades para cada personaje.\n",
        "# La probabilidad más alta es la predicción.\n",
        "y_hat_prob[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxs4EZSBAZoh"
      },
      "outputs": [],
      "source": [
        "# Para la probabilidad de la primer imagen, se ubica su ubicación (Pero no tenemos el nombre del personaje)\n",
        "y_hat = np.argmax(y_hat_prob,axis=1)\n",
        "y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Cómo obtener el nombre del personaje de la predicción?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sUNxLv263yr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBqoGBsIS4Rr"
      },
      "outputs": [],
      "source": [
        "#¿Cómo obtenemos el \"y\" verdadero?\n",
        "# A partir del atributo filanames\n",
        "test_generator.filenames"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Nota:** Los nombres de los personajes de test_generator.filenames tienen barra, extensiones. Por lo que, hay que extraer solo el nombre.\n",
        "Ejemplo:\n",
        "\n",
        "\n",
        "*   De esto --> ['test_images/sideshow_bob_38.jpg']\n",
        "*   A esto --> [sideshow_bob]\n"
      ],
      "metadata": {
        "id": "FUmeJNcr35wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Muy rebuscada esta forma de obtener los nombres de los personajes!\n",
        "# Pero en general cuando tenemos los datos de test no tenemos los nombres\n",
        "# por lo que no tenemos el \"y\" verdadero\n",
        "\n",
        "personajes_test = []\n",
        "\n",
        "# Bucle que recorre todos los nombres de los personajes de test_generator\n",
        "# Para extraer sólo el nombre\n",
        "for file in test_generator.filenames:\n",
        "\n",
        "    # Ubica la ruta del archivo y alamcena solo el nombre,\n",
        "    # por ejemplo: abraham_grampa_simpson_39.jpg\n",
        "\n",
        "    image_name = os.path.basename(file)\n",
        "\n",
        "    # Una vez ubicado el nombre de la img,\n",
        "    # separa los elementos por \"_\", por ejemplo; ['abraham', 'grampa', 'simpson', '39.jpg']\n",
        "    image_name_split = image_name.split(\"_\")\n",
        "\n",
        "    # Extrae el último elemento que corresponde a la extensión de la imagen,\n",
        "    # por ejemplo; ['abraham', 'grampa', 'simpson']\n",
        "    personaje_name_split = image_name_split[:len(image_name_split)-1]\n",
        "\n",
        "    # Nos quedamos con el primer elemento, primer nombre de la lista,\n",
        "    # por ejemplo; abraham\n",
        "    personaje = personaje_name_split[0]\n",
        "\n",
        "    # Bucle que recorre la lista con el nombre del personaje\n",
        "    # desde el primer elemento hasta el final, por ejemplo; ['abraham', 'grampa', 'simpson']\n",
        "    # Para concatenar el nombre con \"_\"\n",
        "    for name in personaje_name_split[1:]:\n",
        "        personaje += \"_\" + name\n",
        "\n",
        "    # Agrega el nombre del personaje en una lista\n",
        "    personajes_test.append(personaje)\n",
        "personajes_test"
      ],
      "metadata": {
        "id": "lC7yce-R3-g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUeviz_CUXlK"
      },
      "outputs": [],
      "source": [
        "# Obtener el \"y\" verdadero\n",
        "# por cada personaje de la predicción ubica el indice\n",
        "# que le corresponde en los datos de train_generator\n",
        "y_test = [train_generator.class_indices[personaje] for personaje in personajes_test]\n",
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3IfjUuI4XnD"
      },
      "source": [
        "# Validar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "_vHwXBcG2OVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat"
      ],
      "metadata": {
        "id": "oBRUeZaw2RID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnXeXHwdyHVx"
      },
      "outputs": [],
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeLeYLYz6ZhO"
      },
      "outputs": [],
      "source": [
        "# Se utiliza la matriz de confusión para evaluar la precisión de una clasificación.\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Necesita dos variables que contengan los valores a comparar\n",
        "cm = confusion_matrix(y_test, y_hat)\n",
        "\n",
        "# Código para realizar la representación gráfica con los resultados\n",
        "# Se crea la varible cmd, que almacena visualization de la Confusion Matrix\n",
        "# Necesita la variable cm que contiene los resultados de la comparación entre los valores reales y predicción\n",
        "# display_labels, se especifica las etiquetas de las categorias que se evalúan.\n",
        "cmd = ConfusionMatrixDisplay(cm)\n",
        "\n",
        "# Con cmd.plot se especifica el mapa de colores reconocido por matplotlib.\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZxGbjG96jR"
      },
      "source": [
        "# Utilizar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Tc5nBqbow8"
      },
      "source": [
        "Se utiliza el ranking de los peores 10 números clasificados con una ANN para evlauar contra este nuevo modelo de red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noOsuU6Tb4GZ"
      },
      "outputs": [],
      "source": [
        "#  test_generator.next(), para observar los resultados de las siguientes 10 imágenes de la predección.\n",
        "batch_test = test_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cefy3ktFb6j6"
      },
      "outputs": [],
      "source": [
        "# plt alias de Matplotlib.\n",
        "# Método figure() crea el espacio para dibujar.\n",
        "# Con figsize=(16,9) se define el ancho y alto del dibujofig = plt.figure(figsize=(16,9))\n",
        "# Observar las primeras 5 imagenes de ese batch\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "# Itera 5 veces\n",
        "for i in range(10):\n",
        "\n",
        "    # ax, gráfico que mostrará las imágenes en 2 filas y 5 columnas\n",
        "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "\n",
        "    # Muestra la imagen\n",
        "    ax.imshow(batch_test[i])\n",
        "\n",
        "    # Ubica por la posición de la imagen el nombre que le corresponde.\n",
        "    numero_clase = y_hat[i]\n",
        "\n",
        "    # A cada imagen le agrega un titulo que sería el nombre del personaje que le corresponde.\n",
        "    ax.set_title(index_to_classes[numero_clase])\n",
        "\n",
        "# Muestra la imagen.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yzVZcZ9-4m"
      },
      "source": [
        "# Conclusión\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWAReOgo-B7b"
      },
      "source": [
        "Se puede observar que con transfer learning se obtuvo un mejor resultado pero aún no es suficiente. Esto es porque la red VGG nunca en el pasado vio los personajes de los simpsons, que son personajes inventados con características que no encontraremos en las imagenes de personas las cuales se usaron para entrenar a este modelo."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}